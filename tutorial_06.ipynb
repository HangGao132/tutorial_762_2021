{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Noisy Data\n",
    "\n",
    "## Clustering: Unsupervised learning - K-means algoirthm\n",
    "\n",
    "**Question**\n",
    "\n",
    "Give the following data: 13,15,16,16,19,20,20,21,22,22,25,25,25,25,30,33,33,35,35,35,35,36,40,45,46,52,70.<br/>\n",
    "Apply K-means clustering algoirthm to smooth the data, where k = 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 2**16\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (27,)\n",
      "After: (27, 1)\n",
      "Print the top 5 data points:\n",
      "[[13]\n",
      " [15]\n",
      " [16]\n",
      " [16]\n",
      " [19]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([13,15,16,16,19,20,20,21,22,22,25,25,25,25,30,33,33,35,35,35,35,36,40,45,46,52,70])\n",
    "# sklearn model will think this is one sample with 27 attributes.\n",
    "print('Before:', X.shape)\n",
    "\n",
    "# Expand the dimension, so we can have a 27x1 matrix (27 samples, each sample has 1 attribute).\n",
    "X = np.expand_dims(X, axis=1)\n",
    "print('After:', X.shape)\n",
    "print('Print the top 5 data points:')\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, random_state=65536)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean = KMeans(n_clusters=3, random_state=random_state)\n",
    "kmean.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: the clusters are not ordered.\n",
    "pred = kmean.predict(X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 61, 20])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute mean for each cluster\n",
    "means = np.zeros(3, dtype=np.int32)\n",
    "for i in range(3):\n",
    "    idx = np.where(pred == i)[0]\n",
    "    mean = X[idx].mean()\n",
    "    means[i] = np.round(mean, decimals=0)\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 37, 37, 37,\n",
       "       37, 37, 37, 37, 37, 37, 37, 37, 61, 61])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map x with its cluster mean value\n",
    "X_smoothed = np.array([means[x] for x in pred])\n",
    "\n",
    "X_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "\n",
    "## Generating data using SMOTE - Synthetic Minority Over-sampling Technique\n",
    "\n",
    "<img src=\"imgs/smote.png\" style=\"height:200px;\">\n",
    "\n",
    "The algorithm of SMOTE:<br/>\n",
    "<img src=\"imgs/smote_algorithm.png\" style=\"width:800px;\"><br/>\n",
    "Source: Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). SMOTE: synthetic minority over-sampling technique. Journal of artificial intelligence research, 16, 321-357."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X, p, k):\n",
    "    \"\"\" Apply minority over-sampling technique - SMOTE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        the samples with a minority class.\n",
    "    p : float\n",
    "        Amount of SMOTE. If p is less than 1, then the synthetic data will generate from p percent of randomized X.\n",
    "    k : int\n",
    "        Number of nearest neighbours.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outputs : ndarray\n",
    "        Synthetic minority class samples\n",
    "    \"\"\"\n",
    "    n_X = len(X)\n",
    "    n_out = int(n_X * p)\n",
    "    n_attributes = X.shape[1]\n",
    "    # randomly choose n_X samples from X with replacement.\n",
    "    indices_outputs = np.random.choice(n_X, size=n_out, replace=True)\n",
    "    outputs = X.copy()[indices_outputs]\n",
    "\n",
    "    # Find k nearest neighbours for all X. \n",
    "    tree = KDTree(X)\n",
    "    k_indices = tree.query(X, k=k, return_distance=False)\n",
    "    gaps = np.random.rand(n_out)\n",
    "    \n",
    "    for i, i_x in enumerate(indices_outputs):\n",
    "        nn = np.random.choice(k_indices[i_x], 1)\n",
    "        dif = X[i_x] - X[nn]\n",
    "        outputs[i] = X[nn] + gaps[i] * dif\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 4)\n",
      "[[5.4 3.9 1.3 0.4]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.4 2.9 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "# Select all sample where class = 0\n",
    "indices = np.where(y_train==0)[0]\n",
    "X0 = X_train[indices]\n",
    "\n",
    "print(X0.shape)\n",
    "\n",
    "print(X0[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, max_depth=5)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 99.05%\n",
      "\n",
      "Accuracy on test set: 97.78%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_train = rf.score(X_train, y_train)\n",
    "print('Accuracy on training set: {:2.2%}\\n'.format(acc_train))\n",
    "acc_test = rf.score(X_test, y_test)\n",
    "print('Accuracy on test set: {:2.2%}\\n'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 4)\n",
      "[[5.15969776 3.78010075 1.5        0.28010075]\n",
      " [5.1042635  3.5        1.4042635  0.2       ]\n",
      " [5.51435389 4.09058981 1.62376408 0.4       ]\n",
      " [4.83795007 3.1        1.56204993 0.2       ]\n",
      " [5.37358708 3.89119569 1.71760861 0.4       ]\n",
      " [5.1        3.7        1.5        0.4       ]\n",
      " [5.21254359 3.76248547 1.56248547 0.2       ]\n",
      " [5.04990696 3.52504652 1.4        0.24990696]\n",
      " [4.5        2.3        1.3        0.3       ]\n",
      " [4.86709413 3.03290587 1.46581175 0.2       ]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate 200% of synthetic data, with k = 5\n",
    "\n",
    "# If the value of an attribute is the same between the targeted point and its neighbour,\n",
    "# the difference for that attribute will be 0.\n",
    "X0_smote = smote(X0, 2.0, 5)\n",
    "\n",
    "print(X0_smote.shape)\n",
    "\n",
    "print(X0_smote[:10])\n",
    "\n",
    "pred = rf.predict(X0_smote)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 4)\n",
      "[[5.57003184 3.84332272 1.7        0.34332272]\n",
      " [4.4        2.98507207 1.31492793 0.2       ]\n",
      " [5.1        3.79034507 1.59034507 0.21930985]\n",
      " [5.1        3.8        1.5620414  0.2379586 ]\n",
      " [5.25188632 3.55188632 1.5        0.2       ]\n",
      " [5.40969028 3.70323009 1.50646019 0.20323009]\n",
      " [4.95038597 3.6        1.4        0.15038597]\n",
      " [4.9        3.1        1.5        0.1728397 ]\n",
      " [5.1        3.5        1.4        0.2       ]\n",
      " [5.4        3.9        1.3        0.4       ]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate 50% of synthetic data, with k = 3\n",
    "\n",
    "# k-neighbours include the targeted point itself,\n",
    "# so k =3 means the target and 2 of its neighbours.\n",
    "# The smaller k gets, the more likely to resample from \n",
    "# the real data.\n",
    "X0_smote = smote(X0, 0.5, 3)\n",
    "\n",
    "print(X0_smote.shape)\n",
    "\n",
    "print(X0_smote[:10])\n",
    "\n",
    "pred = rf.predict(X0_smote)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 4)\n",
      "[[5.1 3.4 1.5 0.2]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.1 3.5 1.4 0.2]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate 100% of synthetic data, with k = 1\n",
    "\n",
    "# When k = 1, the difference should be always 0. \n",
    "# Thus SMOTE is equivalent to resampling \n",
    "# (random choose n samples with replacement).\n",
    "X0_smote = smote(X0, 1, 1)\n",
    "\n",
    "print(X0_smote.shape)\n",
    "\n",
    "print(X0_smote[:10])\n",
    "\n",
    "pred = rf.predict(X0_smote)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
